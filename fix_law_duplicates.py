"""
ì‹¤ì œ ë°ì´í„°ì—ì„œ ë²•ë ¹ëª… ì¤‘ë³µ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ì‹¤ìš©ì ì¸ ìŠ¤í¬ë¦½íŠ¸
"""

from law_name_deduplicator import SimpleLawNameDeduplicator
from typing import List, Dict, Any
import streamlit as st

def process_violation_results_with_deduplication(violation_results: List[Dict]) -> List[Dict]:
    """ìœ„ë²•ì„± ë¶„ì„ ê²°ê³¼ì—ì„œ ë²•ë ¹ëª… ì¤‘ë³µì„ ì œê±°í•˜ê³  í†µí•©"""

    if not violation_results:
        return violation_results

    deduplicator = SimpleLawNameDeduplicator()

    st.write("### ğŸ”§ ë²•ë ¹ëª… ì¤‘ë³µ ì œê±° ì²˜ë¦¬")

    # 1. ëª¨ë“  ë²•ë ¹ëª… ì¶”ì¶œ
    all_law_names = []
    law_name_to_results = {}  # ë²•ë ¹ëª…ë³„ ê´€ë ¨ ê²°ê³¼ë“¤ ë§¤í•‘

    for result in violation_results:
        # ê²°ê³¼ì—ì„œ ë²•ë ¹ëª… ì¶”ì¶œ (ì‹¤ì œ ë°ì´í„° êµ¬ì¡°ì— ë”°ë¼ ì¡°ì • í•„ìš”)
        law_names = extract_law_names_from_result(result)

        for law_name in law_names:
            if law_name not in law_name_to_results:
                law_name_to_results[law_name] = []
            law_name_to_results[law_name].append(result)
            all_law_names.append(law_name)

    st.write(f"ğŸ“Š ì¶”ì¶œëœ ë²•ë ¹ëª…: {len(set(all_law_names))}ê°œ (ì¤‘ë³µ í¬í•¨: {len(all_law_names)}ê°œ)")

    # 2. ì¤‘ë³µ ë¶„ì„ ë° ì œê±°
    analysis = deduplicator.analyze_duplications(list(set(all_law_names)))

    if analysis['reduction_count'] > 0:
        st.success(f"âœ… ì¤‘ë³µ ì œê±° íš¨ê³¼: {analysis['reduction_count']}ê°œ ë²•ë ¹ ì •ë¦¬ ({analysis['reduction_rate']:.1f}% ì ˆì•½)")

        # ì¤‘ë³µ ê·¸ë£¹ í‘œì‹œ
        with st.expander("ğŸ” ì¤‘ë³µ ì œê±° ìƒì„¸", expanded=False):
            for i, group in enumerate(analysis['duplicate_groups'], 1):
                best_name = deduplicator.select_best_name(group)
                st.write(f"**ê·¸ë£¹ {i}**: {best_name}")
                for law in group:
                    st.write(f"  - {law}")

    # 3. í†µí•©ëœ ê²°ê³¼ ìƒì„±
    consolidated_results = consolidate_results_by_law(
        violation_results,
        analysis['duplicate_groups'],
        deduplicator
    )

    st.write(f"ğŸ“‹ ìµœì¢… ê²°ê³¼: {len(consolidated_results)}ê°œ ë²•ë ¹ìœ¼ë¡œ ì •ë¦¬")

    return consolidated_results

def extract_law_names_from_result(result: Dict) -> List[str]:
    """ê²°ê³¼ ë°ì´í„°ì—ì„œ ë²•ë ¹ëª… ì¶”ì¶œ (ì‹¤ì œ ë°ì´í„° êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì • í•„ìš”)"""
    law_names = []

    # ê²°ê³¼ í…ìŠ¤íŠ¸ì—ì„œ ë²•ë ¹ëª… íŒ¨í„´ ì°¾ê¸°
    text_content = ""

    # ì—¬ëŸ¬ í…ìŠ¤íŠ¸ í•„ë“œì—ì„œ ë‚´ìš© ìˆ˜ì§‘
    if isinstance(result, dict):
        for key, value in result.items():
            if isinstance(value, str) and any(keyword in key.lower() for keyword in ['content', 'text', 'summary', 'title']):
                text_content += value + " "
    elif isinstance(result, str):
        text_content = result

    # ë²•ë ¹ëª… íŒ¨í„´ ì¶”ì¶œ
    import re
    patterns = [
        r'([^.\n]*?ë²•ë¥ ?)[.\s,]',
        r'([^.\n]*?ë ¹)[.\s,]',
        r'([^.\n]*?ê·œì¹™)[.\s,]',
        r'([^.\n]*?ì¡°ë¡€)[.\s,]',
        r'(ì§€ë°©ìì¹˜ë²•)',
        r'(ê³µê³µê¸°ê´€ì˜\s*ìš´ì˜ì—\s*ê´€í•œ\s*ë²•ë¥ ?)',
        r'(í–‰ì •ì ˆì°¨ë²•)',
        r'(êµ­ê°€ì¬ì •ë²•)',
    ]

    for pattern in patterns:
        matches = re.findall(pattern, text_content, re.IGNORECASE)
        for match in matches:
            clean_name = re.sub(r'\s+', ' ', match).strip()
            if len(clean_name) >= 3 and clean_name not in law_names:
                law_names.append(clean_name)

    return law_names

def consolidate_results_by_law(violation_results: List[Dict], duplicate_groups: List[List[str]], deduplicator) -> List[Dict]:
    """ì¤‘ë³µ ë²•ë ¹ì„ ê¸°ì¤€ìœ¼ë¡œ ê²°ê³¼ë“¤ì„ í†µí•©"""

    # ê° ê·¸ë£¹ì˜ í‘œì¤€ ë²•ë ¹ëª… ê²°ì •
    law_mapping = {}  # ì›ë³¸ ë²•ë ¹ëª… -> í‘œì¤€ ë²•ë ¹ëª…

    for group in duplicate_groups:
        standard_name = deduplicator.select_best_name(group)
        for law_name in group:
            law_mapping[law_name] = standard_name

    # ê·¸ë£¹í™”ë˜ì§€ ì•Šì€ ë²•ë ¹ë“¤ë„ ë§¤í•‘ì— ì¶”ê°€
    all_laws_in_groups = set()
    for group in duplicate_groups:
        all_laws_in_groups.update(group)

    for result in violation_results:
        law_names = extract_law_names_from_result(result)
        for law_name in law_names:
            if law_name not in all_laws_in_groups:
                law_mapping[law_name] = deduplicator.normalize_law_name(law_name)

    # í‘œì¤€ ë²•ë ¹ëª…ë³„ë¡œ ê²°ê³¼ ê·¸ë£¹í™”
    consolidated = {}

    for result in violation_results:
        law_names = extract_law_names_from_result(result)

        # ì´ ê²°ê³¼ê°€ ì†í•  í‘œì¤€ ë²•ë ¹ëª…ë“¤ ì°¾ê¸°
        standard_laws = set()
        for law_name in law_names:
            if law_name in law_mapping:
                standard_laws.add(law_mapping[law_name])

        # ê° í‘œì¤€ ë²•ë ¹ëª…ì— ì´ ê²°ê³¼ ì¶”ê°€
        for standard_law in standard_laws:
            if standard_law not in consolidated:
                consolidated[standard_law] = {
                    'law_name': standard_law,
                    'original_names': set(),
                    'related_results': [],
                    'total_content_length': 0
                }

            consolidated[standard_law]['original_names'].update(law_names)
            consolidated[standard_law]['related_results'].append(result)

            # ë‚´ìš© ê¸¸ì´ ê³„ì‚° (ëŒ€ëµì )
            content = str(result)
            consolidated[standard_law]['total_content_length'] += len(content)

    # ìµœì¢… ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    final_results = []
    for standard_law, data in consolidated.items():
        final_result = {
            'standard_law_name': standard_law,
            'original_law_names': list(data['original_names']),
            'related_results_count': len(data['related_results']),
            'total_content_length': data['total_content_length'],
            'related_results': data['related_results'][:5],  # ìƒìœ„ 5ê°œë§Œ í¬í•¨
            'summary': f"{standard_law}ì— ëŒ€í•œ {len(data['related_results'])}ê°œ ìœ„ë²• ì‚¬ë¡€"
        }
        final_results.append(final_result)

    # ê´€ë ¨ ê²°ê³¼ ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
    final_results.sort(key=lambda x: x['related_results_count'], reverse=True)

    return final_results

def create_gemini_optimized_prompt(consolidated_results: List[Dict]) -> str:
    """í†µí•©ëœ ê²°ê³¼ë¡œ ìµœì í™”ëœ Gemini í”„ë¡¬í”„íŠ¸ ìƒì„±"""

    if not consolidated_results:
        return "ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

    prompt_parts = []

    # í—¤ë”
    prompt_parts.append("# ì¡°ë¡€ ìœ„ë²•ì„± ì¢…í•© ë¶„ì„ (ìµœì í™”ë¨)\n")

    # ìš”ì•½
    total_laws = len(consolidated_results)
    total_cases = sum(result['related_results_count'] for result in consolidated_results)

    prompt_parts.append(f"""
## ë¶„ì„ ê°œìš”
- ê´€ë ¨ ë²•ë ¹: {total_laws}ê°œ (ì¤‘ë³µ ì œê±° í›„)
- ì´ ìœ„ë²• ì‚¬ë¡€: {total_cases}ê°œ
- ìµœì í™” íš¨ê³¼: ì¤‘ë³µ ë²•ë ¹ í†µí•©ìœ¼ë¡œ ë¶„ì„ íš¨ìœ¨ì„± í–¥ìƒ

## ì£¼ìš” ìœ„ë²• ìœ„í—˜ ë²•ë ¹

""")

    # ìƒìœ„ 10ê°œ ë²•ë ¹ë§Œ í¬í•¨ (Gemini API íš¨ìœ¨ì„±)
    top_results = consolidated_results[:10]

    for i, result in enumerate(top_results, 1):
        prompt_parts.append(f"""
### {i}. {result['standard_law_name']}
- ìœ„ë²• ì‚¬ë¡€ ìˆ˜: {result['related_results_count']}ê°œ
- ì›ë³¸ ë²•ë ¹ëª…: {', '.join(result['original_law_names'][:3])}{'...' if len(result['original_law_names']) > 3 else ''}
- ë‚´ìš© ë¶„ëŸ‰: {result['total_content_length']:,}ì
- ìš”ì•½: {result['summary']}

""")

    # ë¶„ì„ ìš”ì²­
    prompt_parts.append("""
## ë¶„ì„ ìš”ì²­

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ì‚¬í•­ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:

1. **ìœ„ë²•ì„± ìš°ì„ ìˆœìœ„**: ìœ„í—˜ë„ê°€ ë†’ì€ ë²•ë ¹ ìˆœìœ¼ë¡œ í‰ê°€
2. **í†µí•© ë¶„ì„ì˜ ì¥ì **: ì¤‘ë³µ ì œê±°ë¡œ ì–»ì€ ë¶„ì„ í’ˆì§ˆ ê°œì„  íš¨ê³¼
3. **í•µì‹¬ ê°œì„  ë°©ì•ˆ**: ê°€ì¥ ì‹œê¸‰í•œ 3ê°€ì§€ ì¡°ë¡€ ìˆ˜ì •ì‚¬í•­
4. **ë²•ì  ê·¼ê±°**: ê° ìœ„ë²• ìœ„í—˜ì— ëŒ€í•œ êµ¬ì²´ì  ë²•ì  ê·¼ê±°

**ì°¸ê³ ì‚¬í•­**: ì¤‘ë³µëœ ë²•ë ¹ëª…ì´ í•˜ë‚˜ë¡œ í†µí•©ë˜ì–´ ë” ì •í™•í•œ ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.
""")

    final_prompt = "".join(prompt_parts)

    return final_prompt

# ë°ëª¨ í•¨ìˆ˜
def demo_fix_duplicates():
    st.title("ğŸ”§ ì‹¤ì œ ë°ì´í„° ë²•ë ¹ëª… ì¤‘ë³µ í•´ê²°")

    # ìƒ˜í”Œ ë°ì´í„° (ì‹¤ì œ ìœ„ë²•ì„± ë¶„ì„ ê²°ê³¼ í˜•íƒœ ì‹œë®¬ë ˆì´ì…˜)
    sample_results = [
        {
            "content": "ê³µê³µê¸°ê´€ì˜ìš´ì˜ì—ê´€í•œë²•ë¥  ì œ4ì¡°ì— ë”°ë¥´ë©´ ì§€ë°©ìì¹˜ë‹¨ì²´ëŠ”...",
            "summary": "ê¸°ê´€ìœ„ì„ì‚¬ë¬´ ìœ„ë°˜ ì‚¬ë¡€",
            "risk_score": 0.8
        },
        {
            "content": "ê³µê³µê¸°ê´€ì˜ ìš´ì˜ì— ê´€í•œë²•ë¥  ì œ10ì¡° ìœ„ë°˜ìœ¼ë¡œ ì¸í•œ...",
            "summary": "ê¶Œí•œ ìœ„ì„ í•œê³„ ì´ˆê³¼",
            "risk_score": 0.7
        },
        {
            "content": "ê³µê³µê¸°ê´€ì˜ ìš´ì˜ì— ê´€í•œ ë²•ë¥ ì— ë”°ë¥¸ ê°ë…ê¶Œí•œì„...",
            "summary": "ê°ë…ê¶Œí•œ ë²”ìœ„ ìœ„ë°˜",
            "risk_score": 0.6
        },
        {
            "content": "ì§€ë°©ìì¹˜ë²• ì œ22ì¡°ì™€ í–‰ì • ì ˆì°¨ ë²• ê·œì •ì—...",
            "summary": "ì ˆì°¨ì  í•˜ì",
            "risk_score": 0.5
        },
    ]

    st.subheader("ğŸ“Š ìƒ˜í”Œ ë°ì´í„°")
    st.json(sample_results)

    if st.button("ğŸš€ ì¤‘ë³µ ì œê±° ë° ìµœì í™” ì‹¤í–‰"):

        # ì¤‘ë³µ ì œê±° ì²˜ë¦¬
        consolidated = process_violation_results_with_deduplication(sample_results)

        st.subheader("ğŸ“‹ í†µí•© ê²°ê³¼")
        for result in consolidated:
            with st.expander(f"ğŸ“„ {result['standard_law_name']} ({result['related_results_count']}ê°œ ì‚¬ë¡€)", expanded=False):
                st.write(f"**ì›ë³¸ ë²•ë ¹ëª…ë“¤:** {', '.join(result['original_law_names'])}")
                st.write(f"**ê´€ë ¨ ì‚¬ë¡€ ìˆ˜:** {result['related_results_count']}ê°œ")
                st.write(f"**ë‚´ìš© ë¶„ëŸ‰:** {result['total_content_length']:,}ì")
                st.write(f"**ìš”ì•½:** {result['summary']}")

        # ìµœì í™”ëœ Gemini í”„ë¡¬í”„íŠ¸ ìƒì„±
        st.subheader("ğŸ¤– ìµœì í™”ëœ Gemini í”„ë¡¬í”„íŠ¸")
        prompt = create_gemini_optimized_prompt(consolidated)

        st.text_area("ìƒì„±ëœ í”„ë¡¬í”„íŠ¸:", prompt, height=300)

        # ìµœì í™” íš¨ê³¼ í‘œì‹œ
        original_count = len(sample_results)
        consolidated_count = len(consolidated)

        if original_count > consolidated_count:
            st.success(f"""
            ğŸ¯ **ìµœì í™” íš¨ê³¼**
            - ì›ë³¸ ë¶„ì„ ëŒ€ìƒ: {original_count}ê°œ ê²°ê³¼
            - í†µí•© í›„: {consolidated_count}ê°œ ë²•ë ¹ ê·¸ë£¹
            - API í˜¸ì¶œ íš¨ìœ¨ì„±: {((original_count - consolidated_count) / original_count * 100):.1f}% ê°œì„ 
            """)

if __name__ == "__main__":
    demo_fix_duplicates()