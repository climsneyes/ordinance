# ì´ ì½”ë“œë¥¼ Google Colabì— ë³µì‚¬í•´ì„œ ì‹¤í–‰í•˜ì„¸ìš”.
# ëŸ°íƒ€ì„ ìœ í˜•: T4 GPU (í•„ìˆ˜)

import os
import time
import subprocess

# ---------------------------------------------------------
# 1. prepare_dataset.py íŒŒì¼ ìë™ ìƒì„± (ì—…ë¡œë“œ ë¶ˆí•„ìš”!)
# ---------------------------------------------------------
prepare_dataset_code = r'''
import os
import json
import toml
import PyPDF2
import google.generativeai as genai
from tqdm import tqdm
import time
import argparse
import requests

def load_api_key():
    """Load Gemini API key from .streamlit/secrets.toml"""
    try:
        if os.path.exists(".streamlit/secrets.toml"):
            secrets = toml.load(".streamlit/secrets.toml")
            api_key = secrets.get("GOOGLE_API_KEY") or secrets.get("GEMINI_API_KEY")
            if not api_key and "connections" in secrets and "gemini" in secrets["connections"]:
                api_key = secrets["connections"]["gemini"].get("api_key")
            return api_key
    except:
        pass
    return os.getenv("GOOGLE_API_KEY")

def extract_text_from_pdf(pdf_path):
    """Extract text from PDF file"""
    print(f"Extracting text from {pdf_path}...")
    text_chunks = []
    try:
        reader = PyPDF2.PdfReader(pdf_path)
        current_chunk = ""
        for page in tqdm(reader.pages, desc="Reading PDF"):
            text = page.extract_text()
            if not text: continue
            current_chunk += text + "\n"
            if len(current_chunk) > 1500:
                text_chunks.append(current_chunk)
                current_chunk = ""
        if current_chunk:
            text_chunks.append(current_chunk)
        return text_chunks
    except Exception as e:
        print(f"Error reading PDF: {e}")
        return []

def generate_qa_pairs_ollama(chunk, model_name):
    """Generate Q&A pairs using local Ollama"""
    prompt = f"""
    ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ìì¹˜ë²•ê·œ(Local Regulations) ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
    'ìì¹˜ë²•ê·œ ì…ì•ˆ ê¸¸ë¼ì¡ì´'ì˜ ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì„¸ìš”.
    ìì¹˜ë²•ê·œ ì…ì•ˆì— ëŒ€í•œ ì§ˆë¬¸ì— ë‹µë³€í•  ìˆ˜ ìˆëŠ” ëª¨ë¸ì„ íŒŒì¸íŠœë‹í•˜ê¸° ìœ„í•´, 5-8ê°œì˜ ê³ í’ˆì§ˆ ì§ˆë¬¸-ë‹µë³€(Q&A) ìŒì„ ìƒì„±í•´ì£¼ì„¸ìš”.
    
    ì¶œë ¥ í˜•ì‹ì€ 'instruction', 'input', 'output' í‚¤ë¥¼ ê°€ì§„ JSON ê°ì²´ì˜ ë¦¬ìŠ¤íŠ¸ì—¬ì•¼ í•©ë‹ˆë‹¤.
    **ë°˜ë“œì‹œ JSON í˜•ì‹ë§Œ ì¶œë ¥í•˜ì„¸ìš”. ë‹¤ë¥¸ ì„¤ëª…ì€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.**
    
    - 'instruction': ì§ˆë¬¸ ë˜ëŠ” ì§€ì‹œ ì‚¬í•­
    - 'input': í•„ìš”í•œ ê²½ìš° ë¬¸ë§¥ ì •ë³´ (ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´)
    - 'output': ìƒì„¸í•œ ë‹µë³€ (ë°˜ë“œì‹œ í•œêµ­ì–´)
    
    í…ìŠ¤íŠ¸ ë‚´ìš©:
    {chunk[:5000]} 
    
    Output JSON:
    """
    
    try:
        response = requests.post(
            "http://localhost:11434/api/generate",
            json={
                "model": model_name,
                "prompt": prompt,
                "stream": False,
                "format": "json"
            }
        )
        
        if response.status_code == 200:
            result = response.json()
            text_response = result.get("response", "")
            if "```json" in text_response:
                text_response = text_response.split("```json")[1].split("```")[0]
            elif "```" in text_response:
                text_response = text_response.split("```")[1].split("```")[0]
            return json.loads(text_response)
        return []
    except Exception as e:
        print(f"Error generating Q&A with Ollama: {e}")
        return []

def main():
    pdf_path = "2022ë…„_ìì¹˜ë²•ê·œì…ì•ˆê¸¸ë¼ì¡ì´.pdf"
    output_file = "training_data.jsonl"
    
    if not os.path.exists(pdf_path):
        print(f"File not found: {pdf_path}")
        return

    chunks = extract_text_from_pdf(pdf_path)
    print(f"Extracted {len(chunks)} chunks from PDF.")
    
    parser = argparse.ArgumentParser()
    parser.add_argument("--dry-run", action="store_true")
    parser.add_argument("--engine", type=str, default="gemini")
    parser.add_argument("--ollama-model", type=str, default="llama3")
    args = parser.parse_args()

    all_data = []
    with open(output_file, 'w', encoding='utf-8') as f:
        for i, chunk in enumerate(tqdm(chunks, desc="Generating Data")):
            qa_pairs = []
            if args.dry_run:
                qa_pairs = [{"instruction": "Test", "input": "", "output": "Test"}]
            elif args.engine == "ollama":
                qa_pairs = generate_qa_pairs_ollama(chunk, args.ollama_model)
            
            for pair in qa_pairs:
                f.write(json.dumps(pair, ensure_ascii=False) + "\n")
                all_data.append(pair)
            
    print(f"Successfully generated {len(all_data)} training examples.")
    print(f"Saved to {output_file}")

if __name__ == "__main__":
    main()
'''

with open("prepare_dataset.py", "w", encoding="utf-8") as f:
    f.write(prepare_dataset_code)
print("âœ… prepare_dataset.py íŒŒì¼ ìƒì„± ì™„ë£Œ!")

# ---------------------------------------------------------
# 2. Ollama ì„¤ì¹˜ ë° ì‹¤í–‰
# ---------------------------------------------------------
print("â³ Ollama ì„¤ì¹˜ ì¤‘...")
os.system("curl -fsSL https://ollama.com/install.sh | sh")

print("â³ Ollama ì„œë²„ ì‹œì‘ ì¤‘...")
subprocess.Popen(["ollama", "serve"])
time.sleep(10) 

# 3. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (Qwen 2.5)
print("â³ Qwen 2.5 ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘... (ì•½ 3-5ë¶„ ì†Œìš”)")
os.system("ollama pull qwen2.5")

# ---------------------------------------------------------
# 4. PDF íŒŒì¼ ìë™ ì°¾ê¸° ë° ì´ë™
# ---------------------------------------------------------
import shutil

pdf_filename = "2022ë…„_ìì¹˜ë²•ê·œì…ì•ˆê¸¸ë¼ì¡ì´.pdf"
found_path = None

# í˜„ì¬ ìœ„ì¹˜ì— ì—†ìœ¼ë©´ í•˜ìœ„ í´ë” ê²€ìƒ‰
if not os.path.exists(pdf_filename):
    print(f"ğŸ” {pdf_filename} íŒŒì¼ì„ ì°¾ëŠ” ì¤‘...")
    for root, dirs, files in os.walk("."):
        if pdf_filename in files:
            found_path = os.path.join(root, pdf_filename)
            print(f"âœ… íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤: {found_path}")
            # í˜„ì¬ ìœ„ì¹˜ë¡œ ì´ë™
            try:
                shutil.move(found_path, pdf_filename)
                print(f"ğŸ“¦ íŒŒì¼ì„ í˜„ì¬ ìœ„ì¹˜ë¡œ ì´ë™í–ˆìŠµë‹ˆë‹¤.")
            except Exception as e:
                print(f"âš ï¸ íŒŒì¼ ì´ë™ ì‹¤íŒ¨ (ë³µì‚¬ ì‹œë„): {e}")
                try:
                    shutil.copy(found_path, pdf_filename)
                except:
                    pass
            break
else:
    print(f"âœ… {pdf_filename} íŒŒì¼ì´ í˜„ì¬ ìœ„ì¹˜ì— ìˆìŠµë‹ˆë‹¤.")

# 5. ë°ì´í„° ìƒì„± ì‹¤í–‰
if not os.path.exists(pdf_filename):
    print("âŒ [ì˜¤ë¥˜] PDF íŒŒì¼ì´ ì•„ì§ ì—†ìŠµë‹ˆë‹¤!")
    print("ì™¼ìª½ í´ë” ì•„ì´ì½˜ í´ë¦­ -> '2022ë…„_ìì¹˜ë²•ê·œì…ì•ˆê¸¸ë¼ì¡ì´.pdf' íŒŒì¼ì„ ë“œë˜ê·¸í•´ì„œ ë„£ì–´ì£¼ì„¸ìš”.")
    # í˜„ì¬ ë””ë ‰í† ë¦¬ íŒŒì¼ ëª©ë¡ ì¶œë ¥ (ë””ë²„ê¹…ìš©)
    print("í˜„ì¬ í´ë” íŒŒì¼ ëª©ë¡:", os.listdir("."))
else:
    print("ğŸš€ ë°ì´í„° ìƒì„± ì‹œì‘! (ì•½ 10-20ë¶„ ì†Œìš”)")
    os.system("pip install PyPDF2 tqdm google-generativeai")
    os.system("python prepare_dataset.py --engine ollama --ollama-model qwen2.5")
    print("ğŸ‰ ìƒì„± ì™„ë£Œ! 'training_data.jsonl' íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”.")
