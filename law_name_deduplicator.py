"""
ê°„ë‹¨í•œ ë²•ë ¹ëª… ì¤‘ë³µ ì œê±° ìœ í‹¸ë¦¬í‹°
API ì—†ì´ë„ ê¸°ë³¸ì ì¸ ë„ì–´ì“°ê¸° í†µì¼ê³¼ ì¤‘ë³µ ì œê±° ìˆ˜í–‰
"""

import re
from difflib import SequenceMatcher
from typing import List, Dict
import streamlit as st

class SimpleLawNameDeduplicator:
    def __init__(self):
        # ê¸°ë³¸ì ì¸ ë²•ë ¹ëª… ì •ê·œí™” ê·œì¹™
        self.normalization_rules = {
            # ê³µë°± ì •ê·œí™”
            r'\s+': ' ',
            # ê´„í˜¸ ì •ê·œí™”
            r'[\(\ï¼ˆ]([^\)\ï¼‰]*?)[\)\ï¼‰]': r'(\1)',
            # ë²•ë ¹ ì ‘ë¯¸ì‚¬ ì •ê·œí™”
            r'ì—\s*ê´€í•œ\s*ë²•ë¥ ': 'ì— ê´€í•œ ë²•ë¥ ',
            r'ì—\s*ëŒ€í•œ\s*ë²•ë¥ ': 'ì— ëŒ€í•œ ë²•ë¥ ',
            r'ì˜\s*ìš´ì˜\s*ì—\s*ê´€í•œ': 'ì˜ ìš´ì˜ì— ê´€í•œ',
            r'ê³µê³µê¸°ê´€ì˜\s*ìš´ì˜\s*ì—\s*ê´€í•œ\s*ë²•ë¥ ': 'ê³µê³µê¸°ê´€ì˜ ìš´ì˜ì— ê´€í•œ ë²•ë¥ ',
            r'ì§€ë°©\s*ìì¹˜\s*ë²•': 'ì§€ë°©ìì¹˜ë²•',
            r'í–‰ì •\s*ì ˆì°¨\s*ë²•': 'í–‰ì •ì ˆì°¨ë²•',
            r'êµ­ê°€\s*ì¬ì •\s*ë²•': 'êµ­ê°€ì¬ì •ë²•',
        }

    def normalize_law_name(self, law_name: str) -> str:
        """ë²•ë ¹ëª… ì •ê·œí™”"""
        if not law_name or len(law_name.strip()) < 2:
            return law_name

        normalized = law_name.strip()

        # ì •ê·œí™” ê·œì¹™ ì ìš©
        for pattern, replacement in self.normalization_rules.items():
            normalized = re.sub(pattern, replacement, normalized, flags=re.IGNORECASE)

        # ì•ë’¤ ê³µë°± ì œê±°
        normalized = normalized.strip()

        return normalized

    def calculate_similarity(self, str1: str, str2: str) -> float:
        """ë‘ ë¬¸ìì—´ ê°„ ìœ ì‚¬ë„ ê³„ì‚° (0.0 ~ 1.0)"""
        if not str1 or not str2:
            return 0.0

        # ì •ê·œí™”ëœ ë¬¸ìì—´ë¡œ ë¹„êµ
        s1 = self.normalize_law_name(str1).lower()
        s2 = self.normalize_law_name(str2).lower()

        return SequenceMatcher(None, s1, s2).ratio()

    def group_similar_laws(self, law_names: List[str], similarity_threshold: float = 0.85) -> List[List[str]]:
        """ìœ ì‚¬í•œ ë²•ë ¹ëª…ë“¤ì„ ê·¸ë£¹ìœ¼ë¡œ ë¬¶ê¸°"""
        if not law_names:
            return []

        groups = []
        processed = set()

        for i, law1 in enumerate(law_names):
            if law1 in processed:
                continue

            group = [law1]
            processed.add(law1)

            for j, law2 in enumerate(law_names[i+1:], i+1):
                if law2 in processed:
                    continue

                similarity = self.calculate_similarity(law1, law2)
                if similarity >= similarity_threshold:
                    group.append(law2)
                    processed.add(law2)

            groups.append(group)

        return groups

    def deduplicate_laws(self, law_names: List[str], similarity_threshold: float = 0.85) -> List[str]:
        """ë²•ë ¹ëª… ì¤‘ë³µ ì œê±° (ê° ê·¸ë£¹ì—ì„œ ê°€ì¥ í‘œì¤€ì ì¸ ì´ë¦„ ì„ íƒ)"""
        if not law_names:
            return []

        # ìœ ì‚¬í•œ ë²•ë ¹ëª… ê·¸ë£¹í™”
        groups = self.group_similar_laws(law_names, similarity_threshold)

        deduplicated = []

        for group in groups:
            if len(group) == 1:
                deduplicated.append(self.normalize_law_name(group[0]))
            else:
                # ê·¸ë£¹ì—ì„œ ê°€ì¥ í‘œì¤€ì ì¸ ì´ë¦„ ì„ íƒ
                best_name = self.select_best_name(group)
                deduplicated.append(best_name)

        return deduplicated

    def select_best_name(self, law_group: List[str]) -> str:
        """ê·¸ë£¹ì—ì„œ ê°€ì¥ í‘œì¤€ì ì¸ ë²•ë ¹ëª… ì„ íƒ"""
        if len(law_group) == 1:
            return self.normalize_law_name(law_group[0])

        # ì„ íƒ ê¸°ì¤€
        scores = {}

        for law_name in law_group:
            normalized = self.normalize_law_name(law_name)
            score = 0

            # ê¸°ì¤€ 1: ì™„ì „í•œ í˜•íƒœ ì„ í˜¸ (ì§§ì§€ ì•Šê³  ìƒëµë˜ì§€ ì•Šì€)
            if len(normalized) >= 5:
                score += 2

            # ê¸°ì¤€ 2: ì •ì‹ ëª…ì¹­ í˜•íƒœ ì„ í˜¸ ("ë²•ë¥ ", "ë²•", "ë ¹", "ê·œì¹™" í¬í•¨)
            if any(suffix in normalized for suffix in ['ë²•ë¥ ', 'ì‹œí–‰ë ¹', 'ì‹œí–‰ê·œì¹™']):
                score += 3
            elif normalized.endswith('ë²•'):
                score += 2

            # ê¸°ì¤€ 3: ê³µë°±ì´ ì ì ˆíˆ í¬í•¨ëœ í˜•íƒœ ì„ í˜¸
            space_count = normalized.count(' ')
            if 1 <= space_count <= 3:
                score += 1

            # ê¸°ì¤€ 4: ê´„í˜¸ë‚˜ íŠ¹ìˆ˜ë¬¸ìê°€ ì ì€ í˜•íƒœ ì„ í˜¸
            special_char_count = len(re.findall(r'[()ï¼ˆï¼‰\[\]ã€ã€‘]', normalized))
            if special_char_count == 0:
                score += 1

            scores[law_name] = score

        # ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ ë²•ë ¹ëª… ì„ íƒ
        best_law = max(scores, key=scores.get)
        return self.normalize_law_name(best_law)

    def analyze_duplications(self, law_names: List[str]) -> Dict:
        """ì¤‘ë³µ í˜„í™© ë¶„ì„"""
        if not law_names:
            return {'original_count': 0, 'groups': [], 'deduplicated_count': 0}

        groups = self.group_similar_laws(law_names, 0.85)
        deduplicated = self.deduplicate_laws(law_names, 0.85)

        duplicate_groups = [group for group in groups if len(group) > 1]

        return {
            'original_count': len(law_names),
            'deduplicated_count': len(deduplicated),
            'reduction_count': len(law_names) - len(deduplicated),
            'reduction_rate': ((len(law_names) - len(deduplicated)) / len(law_names) * 100) if law_names else 0,
            'duplicate_groups': duplicate_groups,
            'groups': groups,
            'deduplicated_laws': deduplicated
        }


def demo_deduplication():
    """ì¤‘ë³µ ì œê±° ë°ëª¨"""
    st.title("ğŸ”§ ë²•ë ¹ëª… ì¤‘ë³µ ì œê±° ë°ëª¨")

    # í…ŒìŠ¤íŠ¸ìš© ë²•ë ¹ëª… ëª©ë¡
    sample_laws = [
        "ê³µê³µê¸°ê´€ì˜ìš´ì˜ì—ê´€í•œë²•ë¥ ",
        "ê³µê³µê¸°ê´€ì˜ ìš´ì˜ì— ê´€í•œë²•ë¥ ",
        "ê³µê³µê¸°ê´€ì˜ ìš´ì˜ì— ê´€í•œ ë²•ë¥ ",
        "ì§€ë°©ìì¹˜ë²•",
        "ì§€ë°© ìì¹˜ë²•",
        "ì§€ë°©ìì¹˜ ë²•",
        "í–‰ì •ì ˆì°¨ë²•",
        "í–‰ì • ì ˆì°¨ ë²•",
        "êµ­ê°€ì¬ì •ë²•",
        "ì§€ë°©êµë¶€ì„¸ë²•",
        "í—Œë²•"
    ]

    st.subheader("ğŸ“ í…ŒìŠ¤íŠ¸í•  ë²•ë ¹ëª… ëª©ë¡")

    # ì‚¬ìš©ì ì…ë ¥
    law_input = st.text_area(
        "ë²•ë ¹ëª…ì„ í•œ ì¤„ì”© ì…ë ¥í•˜ì„¸ìš”:",
        value="\n".join(sample_laws),
        height=200
    )

    if st.button("ğŸ” ì¤‘ë³µ ì œê±° ì‹¤í–‰"):
        # ì…ë ¥ ì²˜ë¦¬
        input_laws = [law.strip() for law in law_input.split('\n') if law.strip()]

        if not input_laws:
            st.error("ë²•ë ¹ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            return

        # ì¤‘ë³µ ì œê±° ì‹¤í–‰
        deduplicator = SimpleLawNameDeduplicator()
        analysis = deduplicator.analyze_duplications(input_laws)

        # ê²°ê³¼ í‘œì‹œ
        col1, col2, col3 = st.columns(3)

        with col1:
            st.metric("ì›ë³¸ ë²•ë ¹ ìˆ˜", analysis['original_count'])

        with col2:
            st.metric("ì •ë¦¬ëœ ë²•ë ¹ ìˆ˜", analysis['deduplicated_count'])

        with col3:
            st.metric("ì¤‘ë³µ ì œê±°ìœ¨", f"{analysis['reduction_rate']:.1f}%")

        # ì¤‘ë³µ ê·¸ë£¹ ìƒì„¸ ì •ë³´
        if analysis['duplicate_groups']:
            st.subheader("ğŸ” ë°œê²¬ëœ ì¤‘ë³µ ê·¸ë£¹")

            for i, group in enumerate(analysis['duplicate_groups'], 1):
                best_name = deduplicator.select_best_name(group)

                with st.expander(f"ê·¸ë£¹ {i}: {best_name} ({len(group)}ê°œ ìœ ì‚¬)", expanded=True):
                    st.write("**ğŸ¯ ì„ íƒëœ í‘œì¤€ëª…:**")
                    st.success(f"âœ… {best_name}")

                    st.write("**ğŸ“ ì›ë³¸ ë²•ë ¹ëª…ë“¤:**")
                    for law in group:
                        similarity = deduplicator.calculate_similarity(law, best_name)
                        st.write(f"- {law} (ìœ ì‚¬ë„: {similarity:.2f})")

        # ìµœì¢… ì •ë¦¬ëœ ë²•ë ¹ ëª©ë¡
        st.subheader("ğŸ“‹ ìµœì¢… ì •ë¦¬ëœ ë²•ë ¹ ëª©ë¡")

        for i, law in enumerate(analysis['deduplicated_laws'], 1):
            st.write(f"{i}. {law}")

        # ì ˆì•½ íš¨ê³¼ í‘œì‹œ
        if analysis['reduction_count'] > 0:
            st.success(f"""
            ğŸ¯ **ì¤‘ë³µ ì œê±° íš¨ê³¼**
            - {analysis['reduction_count']}ê°œ ì¤‘ë³µ ë²•ë ¹ ì •ë¦¬
            - {analysis['reduction_rate']:.1f}% ë°ì´í„° ì ˆì•½
            - Gemini API í˜¸ì¶œ {analysis['reduction_count']}íšŒ ì ˆì•½ ì˜ˆìƒ
            """)


if __name__ == "__main__":
    demo_deduplication()