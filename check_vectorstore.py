"""
ë²¡í„°ìŠ¤í† ì–´ í™•ì¸ ë° í…ŒìŠ¤íŠ¸ ë„êµ¬
ìƒì„±ëœ PKL íŒŒì¼ì˜ ë‚´ìš©ê³¼ êµ¬ì¡°ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.
"""

import pickle
import numpy as np
import os
from sentence_transformers import SentenceTransformer
import time

def load_and_inspect_vectorstore(pkl_path):
    """ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ ë° êµ¬ì¡° í™•ì¸"""
    if not os.path.exists(pkl_path):
        print(f"âŒ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {pkl_path}")
        return None
    
    print(f"\nğŸ“ ë²¡í„°ìŠ¤í† ì–´ ë¶„ì„: {pkl_path}")
    print(f"ğŸ“Š íŒŒì¼ í¬ê¸°: {os.path.getsize(pkl_path) / (1024*1024):.1f} MB")
    
    try:
        with open(pkl_path, 'rb') as f:
            vectorstore = pickle.load(f)
        
        print(f"âœ… ë¡œë“œ ì„±ê³µ!")
        
        # ê¸°ë³¸ ì •ë³´
        print(f"\nğŸ“‹ ê¸°ë³¸ ì •ë³´:")
        print(f"  - ìƒì„±ì¼ì‹œ: {vectorstore.get('created_at', 'Unknown')}")
        print(f"  - ëª¨ë¸ëª…: {vectorstore.get('model_name', 'Unknown')}")
        print(f"  - ì²­í¬ ìˆ˜: {len(vectorstore.get('chunks', []))}")
        
        # ì„ë² ë”© ì •ë³´
        embeddings = vectorstore.get('embeddings', np.array([]))
        if len(embeddings) > 0:
            print(f"  - ì„ë² ë”© ì°¨ì›: {embeddings.shape[1]}")
            print(f"  - ì„ë² ë”© í˜•íƒœ: {embeddings.shape}")
            print(f"  - ë°ì´í„° íƒ€ì…: {embeddings.dtype}")
        else:
            print(f"  - ì„ë² ë”©: ì—†ìŒ")
        
        # ì„¤ì • ì •ë³´
        config = vectorstore.get('creation_config', {})
        if config:
            print(f"\nâš™ï¸ ìƒì„± ì„¤ì •:")
            for key, value in config.items():
                print(f"  - {key}: {value}")
        
        # ì²­í¬ ìƒ˜í”Œ í™•ì¸
        chunks = vectorstore.get('chunks', [])
        if chunks:
            print(f"\nğŸ“ ì²­í¬ ìƒ˜í”Œ (ì²˜ìŒ 3ê°œ):")
            for i, chunk in enumerate(chunks[:3]):
                print(f"\n  [{i+1}] ì†ŒìŠ¤: {chunk.get('source', 'Unknown')}")
                print(f"      ì œëª©: {chunk.get('title', 'Unknown')}")
                print(f"      í…ìŠ¤íŠ¸: {chunk.get('text', '')[:150]}...")
                print(f"      ê¸¸ì´: {len(chunk.get('text', ''))} ë¬¸ì")
        
        return vectorstore
        
    except Exception as e:
        print(f"âŒ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        return None

def test_search_functionality(vectorstore, query="ê¸°ê´€ìœ„ì„ì‚¬ë¬´"):
    """ê²€ìƒ‰ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    if not vectorstore:
        return
    
    print(f"\nğŸ” ê²€ìƒ‰ í…ŒìŠ¤íŠ¸: '{query}'")
    
    try:
        # ëª¨ë¸ ë¡œë“œ
        model_name = vectorstore.get('model_name', 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')
        print(f"ëª¨ë¸ ë¡œë”©: {model_name}")
        model = SentenceTransformer(model_name)
        
        # ì¿¼ë¦¬ ì„ë² ë”©
        query_embedding = model.encode([query])
        
        # ìœ ì‚¬ë„ ê³„ì‚°
        embeddings = vectorstore.get('embeddings', np.array([]))
        if len(embeddings) == 0:
            print("âŒ ì„ë² ë”©ì´ ì—†ìŠµë‹ˆë‹¤")
            return
        
        similarities = np.dot(query_embedding, embeddings.T).flatten()
        top_indices = np.argsort(similarities)[::-1][:5]
        
        print(f"ğŸ“‹ ìƒìœ„ 5ê°œ ê²°ê³¼:")
        chunks = vectorstore.get('chunks', [])
        
        for i, idx in enumerate(top_indices):
            similarity = similarities[idx]
            chunk = chunks[idx]
            
            print(f"\n  [{i+1}] ìœ ì‚¬ë„: {similarity:.4f}")
            print(f"      ì†ŒìŠ¤: {chunk.get('source', 'Unknown')}")
            print(f"      ì œëª©: {chunk.get('title', 'Unknown')}")
            print(f"      í…ìŠ¤íŠ¸: {chunk.get('text', '')[:200]}...")
            
    except Exception as e:
        print(f"âŒ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")

def compare_vectorstores(pkl_paths):
    """ì—¬ëŸ¬ ë²¡í„°ìŠ¤í† ì–´ ë¹„êµ"""
    print(f"\nğŸ“Š ë²¡í„°ìŠ¤í† ì–´ ë¹„êµ ë¶„ì„")
    print("=" * 60)
    
    stores = {}
    for path in pkl_paths:
        if os.path.exists(path):
            stores[path] = load_and_inspect_vectorstore(path)
    
    if len(stores) < 2:
        print("ë¹„êµí•  ë²¡í„°ìŠ¤í† ì–´ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return
    
    # ë¹„êµ í‘œ ìƒì„±
    print(f"\nğŸ“‹ ìš”ì•½ ë¹„êµ:")
    print(f"{'íŒŒì¼ëª…':<30} {'í¬ê¸°(MB)':<10} {'ì²­í¬ìˆ˜':<8} {'ì„ë² ë”©ì°¨ì›':<10}")
    print("-" * 60)
    
    for path, store in stores.items():
        filename = os.path.basename(path)
        size_mb = os.path.getsize(path) / (1024*1024)
        chunks_count = len(store.get('chunks', [])) if store else 0
        embeddings = store.get('embeddings', np.array([])) if store else np.array([])
        embedding_dim = embeddings.shape[1] if len(embeddings) > 0 else 0
        
        print(f"{filename:<30} {size_mb:<10.1f} {chunks_count:<8} {embedding_dim:<10}")

def analyze_chunk_distribution(vectorstore):
    """ì²­í¬ ë¶„í¬ ë¶„ì„"""
    if not vectorstore:
        return
    
    chunks = vectorstore.get('chunks', [])
    if not chunks:
        return
    
    print(f"\nğŸ“ˆ ì²­í¬ ë¶„í¬ ë¶„ì„:")
    
    # ê¸¸ì´ ë¶„í¬
    lengths = [len(chunk.get('text', '')) for chunk in chunks]
    print(f"  - í‰ê·  ê¸¸ì´: {np.mean(lengths):.0f} ë¬¸ì")
    print(f"  - ìµœì†Œ ê¸¸ì´: {min(lengths)} ë¬¸ì")
    print(f"  - ìµœëŒ€ ê¸¸ì´: {max(lengths)} ë¬¸ì")
    print(f"  - ì¤‘ê°„ê°’: {np.median(lengths):.0f} ë¬¸ì")
    
    # ì†ŒìŠ¤ë³„ ë¶„í¬
    sources = {}
    for chunk in chunks:
        source = chunk.get('source', 'Unknown')
        sources[source] = sources.get(source, 0) + 1
    
    print(f"\n  ğŸ“š ì†ŒìŠ¤ë³„ ì²­í¬ ìˆ˜:")
    for source, count in sources.items():
        print(f"    - {source}: {count}ê°œ")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸ” ë²¡í„°ìŠ¤í† ì–´ ê²€ì‚¬ ë„êµ¬")
    print("=" * 50)
    
    # í™•ì¸í•  PKL íŒŒì¼ë“¤
    pkl_files = [
        'jachi_case_free_vectorstore.pkl',
        'lawcase_free_vectorstore.pkl'
    ]
    
    # ê° íŒŒì¼ ê°œë³„ ë¶„ì„
    stores = {}
    for pkl_file in pkl_files:
        store = load_and_inspect_vectorstore(pkl_file)
        if store:
            stores[pkl_file] = store
            analyze_chunk_distribution(store)
    
    # ë¹„êµ ë¶„ì„
    if len(stores) > 1:
        compare_vectorstores(pkl_files)
    
    # ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    for pkl_file, store in stores.items():
        print(f"\n" + "="*60)
        print(f"ğŸ” {pkl_file} ê²€ìƒ‰ í…ŒìŠ¤íŠ¸")
        test_search_functionality(store, "ê¸°ê´€ìœ„ì„ì‚¬ë¬´")
        test_search_functionality(store, "ìƒìœ„ë²•ë ¹ ìœ„ë°°")
    
    print(f"\nâœ… ë²¡í„°ìŠ¤í† ì–´ ê²€ì‚¬ ì™„ë£Œ!")

if __name__ == "__main__":
    main()